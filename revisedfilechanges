import os
import uuid
import asyncio
import secrets
from datetime import datetime, timedelta
from typing import Dict, Optional, List, Tuple
from fastapi import FastAPI, BackgroundTasks, WebSocket, HTTPException, UploadFile, File, APIRouter, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
import logging
from app.file_processor import FileProcessor
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing
import asyncio
from enum import Enum
import logging
from typing import Dict, Optional
import os
import time
from functools import partial

import aiofiles
from typing import AsyncGenerator, Dict
from fastapi import UploadFile, File, HTTPException, BackgroundTasks
import os
import logging
import uuid

import aiofiles
from typing import AsyncGenerator, Dict
from fastapi import UploadFile, File, HTTPException, BackgroundTasks
import os
import logging
import uuid
from enum import Enum

WEBSOCKET_TIMEOUT = 30  # seconds
UPLOAD_TIMEOUT = 60    # seconds
PROCESSING_TIMEOUT = 45  # seconds
SESSION_VALIDATION_TIMEOUT = 5  # seconds

class FileStatus(Enum):
    """Enum for tracking file processing status"""
    UPLOADING = "uploading"
    UPLOAD_COMPLETED = "upload_completed"
    PROCESSING = "processing"
    PROCESSING_COMPLETED = "processing_completed"
    ERROR = "error"

class ProcessingStatus(Enum):
    """Status tracking for file processing"""
    QUEUED = "queued"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

class ProcessingTask:
    """Task information for file processing"""
    def __init__(self, file_path: str, client_id: str, unique_id: str):
        self.file_path = file_path
        self.client_id = client_id
        self.unique_id = unique_id
        self.status = ProcessingStatus.QUEUED
        self.progress = 0
        self.error = None
        self.start_time = None
        self.end_time = None
        self.retries = 0
        self.max_retries = 3

class FileProcessingManager:
    def __init__(self):
        cpu_count = multiprocessing.cpu_count()
        self.thread_pool = ThreadPoolExecutor(
            max_workers=cpu_count * 2,
            thread_name_prefix="file_processor"
        )
        self.processing_tasks: Dict[str, ProcessingTask] = {}
        self.semaphore = asyncio.Semaphore(cpu_count * 2)
        self.logger = logging.getLogger(__name__)

    async def process_file(self, file_path: str, client_id: str, unique_id: str):
        """Process file with proper resource management"""
        try:
            async with self.semaphore:
                task = ProcessingTask(file_path, client_id, unique_id)
                self.processing_tasks[unique_id] = task
                
                # Update status to PROCESSING
                await session_manager.update_file_status(
                    client_id, 
                    unique_id, 
                    FileStatus.PROCESSING
                )
                
                # Use thread pool for file processing
                loop = asyncio.get_running_loop()
                result = await loop.run_in_executor(
                    self.thread_pool,
                    self._process_file_in_thread,
                    task
                )
                
                if result.get('success'):
                    await session_manager.update_file_status(
                        client_id,
                        unique_id,
                        FileStatus.PROCESSING_COMPLETED
                    )
                    return result
                else:
                    raise Exception(result.get('error', 'Processing failed'))

        except Exception as e:
            self.logger.error(f"Processing error for {file_path}: {str(e)}")
            await session_manager.update_file_status(
                client_id,
                unique_id,
                FileStatus.ERROR,
                str(e)
            )
            raise
        finally:
            # Cleanup
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except Exception as e:
                    self.logger.error(f"Error cleaning up file {file_path}: {e}")
            
            self.processing_tasks.pop(unique_id, None)

    def _process_file_in_thread(self, task: ProcessingTask) -> dict:
        """Handle file processing in thread pool"""
        try:
            file_extension = os.path.splitext(task.file_path)[1].lower()
            
            if file_extension == '.pdf':
                return self._process_pdf(task.file_path)
            elif file_extension == '.docx':
                return self._process_docx(task.file_path)
            else:
                return self._process_image(task.file_path)
                
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _process_pdf(self, file_path: str) -> dict:
        """Process PDF file"""
        try:
            # Add your PDF processing logic here
            # This is just a simulation
            time.sleep(2)  # Simulate processing
            return {
                'success': True,
                'file_unique_id': os.path.basename(file_path),
                'num_chunks': 20,
                'message': "Successfully processed PDF"
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _process_docx(self, file_path: str) -> dict:
        """Process DOCX file"""
        try:
            # Add your DOCX processing logic here
            time.sleep(1)  # Simulate processing
            return {
                'success': True,
                'file_unique_id': os.path.basename(file_path)
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _process_image(self, file_path: str) -> dict:
        """Process image file"""
        try:
            # Add your image processing logic here
            time.sleep(1)  # Simulate processing
            return {
                'success': True,
                'file_unique_id': os.path.basename(file_path)
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    async def shutdown(self):
        """Graceful shutdown of processing resources"""
        self.thread_pool.shutdown(wait=True)

# Configuration Constants
UPLOAD_DIR = "uploads"
MAX_PDF_SIZE = 100 * 1024 * 1024  # 5 MB
MAX_DOCX_SIZE = 5 * 1024 * 1024  # 5 MB
MAX_IMAGE_SIZE = 2 * 1024 * 1024  # 2 MB
ALLOWED_EXTENSIONS = {
    'documents': ['.pdf', '.docx'],
    'images': ['.jpg', '.jpeg', '.png', '.gif']
}
WARNING_TIME = timedelta(minutes=1)
TIMEOUT_TIME = timedelta(minutes=2)
CLEANUP_INTERVAL = 10
BASE_PERSIST_DIR = "chroma_storage"

class ProcessingTask:
    """Task information for file processing"""
    def __init__(self, file_path: str, client_id: str, unique_id: str):
        self.file_path = file_path
        self.client_id = client_id
        self.unique_id = unique_id
        self.status = ProcessingStatus.QUEUED
        self.progress = 0
        self.error = None
        self.start_time = None
        self.end_time = None
        self.retries = 0
        self.max_retries = 3

# Initialize logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Router setup
router = APIRouter(
    tags=["Skill"],
    responses={
        400: {"description": "Bad Request"},
        500: {"description": "Internal Server Error - da skills"},
    },
)

processing_manager = FileProcessingManager()




def create_app():
    """Create and configure FastAPI application"""
    app = FastAPI(
        title="Assistant",
        version="0.0.0",
        description="Assistant",
    )

    # Configure CORS
    origins = [
            "http://localhost:8000",
            "http://127.0.0.1:8000",
    ]

    app.add_middleware(
        CORSMiddleware,
        allow_origins=origins,
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    app.include_router(router=router)


    @app.on_event("startup")
    async def startup_event():
        """Initialize necessary services on startup"""
        logger.info("Starting Digital Assistant Skills service")
        await session_manager.start_cleanup_task()

    @app.on_event("shutdown")
    async def shutdown_event():
        """Cleanup resources on shutdown"""
        logger.info("Shutting down Digital Assistant Skills service")
        if session_manager.cleanup_task:
            session_manager.cleanup_task.cancel()
        await processing_manager.shutdown()
        
        return app

# First, let's define the SessionData class
class SessionData:
    """Session data storage class"""
    def __init__(self, client_id: str, encryption_key: str):
        self.client_id = client_id
        self.encryption_key = encryption_key
        self.file_unique_id = None
        self.files: Dict[str, Dict[str, str | FileStatus]] = {}
        self.last_activity = datetime.utcnow()
        self.warning_sent = False
        self.latest_req_id = 2

    def add_file(self, file_unique_id: str, file_name: str, file_description: str = ""):
        """Add file information to session"""
        self.files[file_unique_id] = {
            "file_name": file_name,
            "file_description": file_description,
            "status": FileStatus.UPLOADING,
            "error_message": None
        }
    def update_file_status(self, file_unique_id: str, status: FileStatus, error_message: str = None):
        """Update file processing status"""
        if file_unique_id in self.files:
            self.files[file_unique_id]["status"] = status
            if error_message:
                self.files[file_unique_id]["error_message"] = error_message
    def get_file_status(self, file_unique_id: str) -> Optional[FileStatus]:
        """Get current status of a file"""
        if file_unique_id in self.files:
            return self.files[file_unique_id]["status"]
        return None
    
    
    def update_activity(self, req_id: str):
        """Update session activity timestamp"""
        self.last_activity = datetime.utcnow()
        self.latest_req_id = req_id
        self.warning_sent = False

class SessionManager:
    """Manage WebSocket sessions and cleanup"""
    def __init__(self):
        self.sessions: Dict[str, SessionData] = {}
        self.client_session_map: Dict[str, str] = {}  # Maps client_id to session_id
        self.active_websockets: Dict[str, WebSocket] = {}  # Maps session_id to WebSocket
        self.cleanup_task: Optional[asyncio.Task] = None

    def create_session(self, websocket: WebSocket) -> Tuple[str, str]:
        """
        Create new session with websocket connection
        Returns:
            Tuple[str, str]: (session_id, client_id)
        """
        session_id = str(uuid.uuid4())
        client_id = str(uuid.uuid4())
        encryption_key = secrets.token_hex(16)
        
        # Initialize session data
        self.sessions[session_id] = SessionData(client_id, encryption_key)
        self.client_session_map[client_id] = session_id
        self.active_websockets[session_id] = websocket
        
        logger.info(f"Created new session. Session ID: {session_id}, Client ID: {client_id}")
        return session_id, client_id

    async def update_file_status(self, client_id: str, file_unique_id: str, status: FileStatus, error_message: str = None):
        """
        Update file status with proper error handling and logging
        Args:
            client_id: Client identifier
            file_unique_id: Unique identifier for the file
            status: New status to set
            error_message: Optional error message if status is ERROR
        """
        try:
            session = self.get_session_by_client_id(client_id)
            logger.info(f"Updating file status for {file_unique_id} to {status}")
            
            if not session:
                logger.error(f"No session found for client {client_id}")
                return
                
            # session.update_file_status(file_unique_id, status, error_message)
            
            # Send status update via WebSocket
            session_id = self.get_session_id_by_client_id(client_id)
            websocket = self.active_websockets.get(session_id)
            
            if websocket:
                try:
                    await websocket.send_json({
                        "eventtype": "file_status_update",
                        "file_unique_id": file_unique_id,
                        "status": status.value,
                        "error_message": error_message,
                        "channel": "main"
                    })
                    logger.info(f"Sent status update {status} for file {file_unique_id}")
                except Exception as e:
                    logger.error(f"Error sending file status update: {e}")
        except Exception as e:
            logger.error(f"Error updating file status: {e}")
            raise

    def get_session_by_client_id(self, client_id: str) -> Optional[SessionData]:
        """
        Retrieve session data using client ID
        Args:
            client_id: Client identifier
        Returns:
            Optional[SessionData]: Session data if found, None otherwise
        """
        session_id = self.client_session_map.get(client_id)
        if session_id:
            return self.sessions.get(session_id)
        return None

    def get_session_id_by_client_id(self, client_id: str) -> Optional[str]:
        """
        Get session ID using client ID
        Args:
            client_id: Client identifier
        Returns:
            Optional[str]: Session ID if found, None otherwise
        """
        return self.client_session_map.get(client_id)

    def get_session_by_id(self, session_id: str) -> Optional[SessionData]:
        """
        Retrieve session data using session ID
        Args:
            session_id: Session identifier
        Returns:
            Optional[SessionData]: Session data if found, None otherwise
        """
        return self.sessions.get(session_id)

    async def update_activity(self, session_id: str, latest_req_id: str):
        """
        Update session activity timestamp and request ID
        Args:
            session_id: Session identifier
            latest_req_id: Latest request identifier
        Raises:
            ValueError: If session ID is invalid
        """
        logger.info(f"Updating activity for session {session_id}")
        try:
            session = self.get_session_by_id(session_id)
            if session:
                session.update_activity(latest_req_id)
                logger.info(f"Updated activity for session {session_id} at {session.last_activity}")
            else:
                raise ValueError("Invalid session ID")
        except Exception as e:
            logger.error(f"Error updating activity for session {session_id}: {e}")
            raise

    async def cleanup_session(self, session_id: str):
        """
        Remove session and its associated data
        Args:
            session_id: Session identifier
        """
        if session_id in self.sessions:
            # Remove from active websockets
            self.active_websockets.pop(session_id, None)
            await purge_chroma_collections(session_id)
            # Remove client mapping
            client_id = self.sessions[session_id].client_id
            self.client_session_map.pop(client_id, None)
            
            # Remove session data
            del self.sessions[session_id]
            logger.info(f"Removed session {session_id}")

    async def start_cleanup_task(self):
        """Initialize the cleanup task"""
        if self.cleanup_task is None:
            self.cleanup_task = asyncio.create_task(self._cleanup_idle_sessions())
            logger.info("Started session cleanup task")

    async def _cleanup_idle_sessions(self):
        """
        Monitors and cleans up idle sessions
        - Checks session activity duration
        - Sends warning messages before timeout
        - Removes expired sessions
        """
        logger.info("Starting cleanup task")
        while True:
            try:
                current_time = datetime.utcnow()
                sessions_to_remove = []

                for session_id, session in self.sessions.items():
                    idle_duration = current_time - session.last_activity
                    latest_req_id = session.latest_req_id

                    logger.info(f"Session {session_id} idle for {idle_duration}")

                    if idle_duration >= TIMEOUT_TIME:
                        logger.info(f"Session {session_id} marked for removal due to inactivity")
                        sessions_to_remove.append(session_id)
                        websocket = self.active_websockets.get(session_id)

                        if websocket:
                            try:
                                await websocket.send_json({
                                    "id": latest_req_id,
                                    "chunk": "your session has expired due to inactivity, i will go",
                                    "end": False,
                                    "eventtype": "session_expiry",
                                    "channel": "main",
                                    "kb": "system"
                                })
                                logger.info(f"Session {session_id} expired due to inactivity")
                            except Exception as e:
                                logger.error(f"Error sending expiry message to session {session_id}: {e}")
                                sessions_to_remove.append(session_id)

                    elif idle_duration >= WARNING_TIME and not session.warning_sent:
                        # Send warning message
                        session.warning_sent = True
                        logger.info(f"Warning sent to session {session_id}")
                        websocket = self.active_websockets.get(session_id)
                        
                        if websocket:
                            try:
                                logger.info(f"Sending warning to session {session_id}")
                                remaining_mins = (TIMEOUT_TIME - idle_duration).seconds // 60
                                logger.info(f"idle_duration: {idle_duration}")
                                logger.info(f"Remaining minutes: {remaining_mins}")
                                
                                await websocket.send_json({
                                    "id": latest_req_id + 1,
                                    "chunk": f"your session will timeout in {remaining_mins} minutes",
                                    "end": False,
                                    "eventtype": "session_warning",
                                    "channel": "main",
                                    "kb": "system"
                                })
                                logger.info(f"Warning sent to session {session_id}: {remaining_mins}")
                            except Exception as e:
                                logger.error(f"Error sending warning to session {session_id}: {e}")
                                sessions_to_remove.append(session_id)

                # Clean up marked sessions
                for session_id in sessions_to_remove:
                    await self.cleanup_session(session_id)
                    logger.info(f"Session {session_id} cleaned up due to inactivity")

                # Wait before next cleanup check
                await asyncio.sleep(CLEANUP_INTERVAL)
            except Exception as e:
                logger.error(f"Error in cleanup: {e}")
                await asyncio.sleep(CLEANUP_INTERVAL)

# Initialize the session manager
session_manager = SessionManager()


async def get_file_type(filename: str) -> str:
    """
    Determine file type based on extension
    Args:
        filename: Name of the file
    Returns:
        str: File type ('document', 'image', or 'unknown')
    """
    ext = os.path.splitext(filename)[1].lower()
    if ext in ALLOWED_EXTENSIONS['documents']:
        return 'document'
    elif ext in ALLOWED_EXTENSIONS['images']:
        return 'image'
    return 'unknown'

# Cleanup utility
async def cleanup_temp_files():
    """Cleanup temporary files periodically"""
    while True:
        try:
            current_time = datetime.utcnow()
            for root, _, files in os.walk(UPLOAD_DIR):
                for file in files:
                    if file.endswith('.temp'):
                        file_path = os.path.join(root, file)
                        file_time = datetime.fromtimestamp(
                            os.path.getctime(file_path)
                        )
                        if current_time - file_time > timedelta(hours=1):
                            os.remove(file_path)
        except Exception as e:
            logger.error(f"Error in cleanup: {e}")
        finally:
            await asyncio.sleep(3600)  # Run every hour


async def handle_file_processing(file_path: str, client_id: str, unique_id: str):
    try:
        async with asyncio.timeout(PROCESSING_TIMEOUT):
            result = await processing_manager.process_file(file_path, client_id, unique_id)
            
            session = session_manager.get_session_by_client_id(client_id)
            if session and result:
                session.file_unique_id = result.get('file_unique_id')
                
    except asyncio.TimeoutError:
        logger.error(f"Processing timeout for file {file_path}")
        await session_manager.update_file_status(
            client_id,
            unique_id,
            FileStatus.ERROR,
            "Processing timed out"
        )
    except Exception as e:
        logger.error(f"Processing error for {file_path}: {str(e)}")
        await session_manager.update_file_status(
            client_id,
            unique_id,
            FileStatus.ERROR,
            str(e)
        )
async def process_pdf(file_path: str, unique_id: str) -> dict:
    """Process PDF file and store in ChromaDB"""
    try:
        # PDF processing implementation would go here
        # Add delay of 20 seconds to simulate processing
        await asyncio.sleep(10)
        return {
                "filename": os.path.basename(file_path),
                "file_unique_id": unique_id,
                "num_chunks": "20",
                "status": "success",
                "message": "Successfully processed PDF and stored in ChromaDB"
            }
    except Exception as e:
        logger.error(f"Error processing PDF file: {e}")
        raise

async def purge_chroma_collections(file: str) -> dict:
    """Purge ChromaDB collections"""
    try:
        # Purge collections implementation would go here
        await asyncio.sleep(20)
        return {"status": "success", "message": "Successfully purged collections"}
    except Exception as e:
        logger.error(f"Error purging collections: {e}")
        raise
async def process_docx(file_path: str, unique_id: str) -> dict:
    """Process DOCX file and store in ChromaDB"""
    try:
        # DOCX processing implementation would go here
        return {"file_unique_id": unique_id}
    except Exception as e:
        logger.error(f"Error processing DOCX file: {e}")
        raise

async def process_image(file_path: str, unique_id: str) -> dict:
    """Process image file and store in ChromaDB"""
    try:
        # Image processing implementation would go here
        return {"file_unique_id": unique_id}
    except Exception as e:
        logger.error(f"Error processing image file: {e}")
        raise

    

async def iterate_chunks(file: UploadFile, chunk_size: int) -> AsyncGenerator[bytes, None]:
    """
    Safely iterate over file chunks with error handling
    Args:
        file: UploadFile object
        chunk_size: Size of each chunk in bytes
    Yields:
        bytes: File chunks
    """
    try:
        while chunk := await file.read(chunk_size):
            yield chunk
    except Exception as e:
        logger.error(f"Error reading file chunk: {e}")
        raise

async def cleanup_temp_file(file_path: str) -> None:
    """
    Safely cleanup temporary file
    Args:
        file_path: Path to the temporary file
    """
    if file_path and os.path.exists(file_path):
        try:
            os.remove(file_path)
            logger.info(f"Cleaned up temporary file: {file_path}")
        except Exception as e:
            logger.error(f"Error cleaning up temporary file {file_path}: {e}")

def secure_filename(filename: str) -> str:
    """
    Make filename secure by removing potentially dangerous characters
    Args:
        filename: Original filename
    Returns:
        str: Sanitized filename
    """
    # Remove any path components
    filename = os.path.basename(filename)
    
    # Replace potentially dangerous characters
    filename = "".join(c for c in filename if c.isalnum() or c in "._- ")
    
    # Limit length
    max_length = 255 - 37  # Leave room for UUID
    if len(filename) > max_length:
        name, ext = os.path.splitext(filename)
        filename = name[:max_length-len(ext)] + ext
        
    return filename.strip()


from typing import Optional, Set, Dict, Any
from pydantic import BaseModel

class ConversationTurn(BaseModel):
    """Model for conversation turns"""
    role: str
    content: str

async def determine_intent(persona: str, skill: str, user_input: str, conversation_history: List[ConversationTurn]) -> Any:
    """
    Determine the intent of user input
    This is a placeholder for the actual intent determination logic
    """
    # Intent determination logic would go here
    return None

async def compute_genai_response(request: Dict[str, Any], websocket: WebSocket, session_id: str):
    """
    Compute and stream AI response
    Args:
        request: Request data from client
        websocket: WebSocket connection
        session_id: Session identifier
    """
    try:
        # Extract request data
        req_id = request["id"]
        user_input = request['question']
        conversation_history = [ConversationTurn(**turn) for turn in request['conversation_history']]
        custom_instruction = request.get('custom_instruction')
        logger.info(f"Conversation history: {conversation_history}")
        
        # Extract user context
        persona = request['digital_persona']
        skill = request['skill']
        intent = request.get('intent')
        speech_mode = request.get('speech_mode')
        input_file_unique_id = request.get('input_file_unique_id')
        output_file_unique_id = request.get('output_file_unique_id')
        image_base64 = request.get('image_base64')
        input_file_name = request.get('input_file_name')

        # Get session data
        session = session_manager.get_session_by_id(session_id)
        if not session:
            raise ValueError("Session not found")
            
        client_id = session.client_id
        encryption_key = session.encryption_key
        files = session.files
        
        logger.info(f"Client ID: {client_id}, Encryption key: {encryption_key}")
        for file_unique_id, file_info in files.items():
            logger.info(f"File Unique ID: {file_unique_id}, File Name: {file_info['file_name']}")
            
        logger.info(f"outside speech model mode: {speech_mode}")
        logger.info(f"inside speech mode: {speech_mode}")

        # Set default action and prompt
        action = "chitchat"
        prompt = "chitchat"
        standalone_question = user_input
        logger.info(f"User input: {user_input}")

        # Execute action
        await execute_action(req_id, persona, skill, action, prompt, standalone_question, conversation_history, websocket)

        logger.info(f"Response computed for request ID: {req_id}")
    except Exception as e:
        logger.exception(e)
        # Handle error response to client
        await send_error_message(websocket, req_id, str(e))

async def execute_action(req_id: str, persona: str, skill: str, action: str, prompt: str, 
                        standalone_question: str, conversation_history: List[ConversationTurn], websocket: WebSocket):
    """
    Execute the determined action
    This is a placeholder for action execution logic
    """
    #add delay of 5 seconds to simulate processing
    await asyncio.sleep(20)
    await websocket.send_json({
            "id": req_id,   
            "chunk": "IM HERE ALL DAY LONG",
            "end": True
        })
    pass

async def send_error_message(websocket: WebSocket, req_id: str, error_msg: str):
    """
    Send error message to client
    """
    try:
        await websocket.send_json({
            "id": req_id,
            "error": error_msg,
            "eventtype": "error",
            "channel": "main",
            "kb": "system"
        })
    except Exception as e:
        logger.error(f"Error sending error message: {e}")

@router.websocket("/liveai/digital/assistant-skills/stream")
async def stream(websocket: WebSocket):
    await websocket.accept()
    session_id, client_id = session_manager.create_session(websocket)
    background_tasks: Set[asyncio.Task] = set()
    await websocket.send_json({
        "eventtype": "init_session",
        "client_id": client_id,
        "channel": "contextmemory",
    })

    try:
        while True:
            try:
                session = session_manager.get_session_by_client_id(client_id)
                session_id = session_manager.get_session_id_by_client_id(client_id)
                encryption_key = session.encryption_key
                unique_file_id = session.file_unique_id

                logger.info(f"Session ID: {session_id}, Encryption key: {encryption_key}, File unique ID: {unique_file_id}")

                # Wait for next message
                async with asyncio.timeout(WEBSOCKET_TIMEOUT):
                    request = await websocket.receive_json()
                    
                # Message received - reset activity timestamp
                await session_manager.update_activity(session_id, request["id"])
                
                # Process message
                task = asyncio.create_task(
                    compute_genai_response(request, websocket, session_id)
                )
                background_tasks.add(task)
                task.add_done_callback(background_tasks.discard)

            except asyncio.TimeoutError:
                # No message received in WEBSOCKET_TIMEOUT seconds
                # Check if session is still active
                session = session_manager.get_session_by_id(session_id)
                if session:
                    current_time = datetime.utcnow()
                    idle_duration = current_time - session.last_activity
                    
                    if idle_duration < TIMEOUT_TIME:
                        # Session still valid, continue waiting
                        continue
                    else:
                        # Session expired
                        await send_error_message(
                            websocket,
                            "timeout",
                            "Session expired due to inactivity"
                        )
                        break

            except Exception as e:
                logger.error(f"Error processing message: {str(e)}")
                await send_error_message(websocket, "error", str(e))

    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected for session {session_id}")
    finally:
        # Cleanup code
        await handle_session_cleanup(session_id, background_tasks)

# @router.websocket("/liveai/digital/assistant-skills/stream")
# async def stream(websocket: WebSocket):
#     """
#     Handle WebSocket connection for streaming responses
#     Args:
#         websocket: WebSocket connection
#     """
#     await websocket.accept()
#     session_id, client_id = session_manager.create_session(websocket)

#     logger.info(f"WebSocket connection established for session {session_id}")
#     logger.info(f"Generated client_id: {client_id}")

#     # Send initial session information to the client
#     await websocket.send_json({
#         "eventtype": "init_session",
#         "client_id": client_id,
#         "channel": "contextmemory",
#     })

#     background_tasks: Set[asyncio.Task] = set()
#     try:
#         while True:
#             # Get session data
            
#             session = session_manager.get_session_by_client_id(client_id)
#             session_id = session_manager.get_session_id_by_client_id(client_id)
#             encryption_key = session.encryption_key
#             unique_file_id = session.file_unique_id

#             logger.info(f"Session ID: {session_id}, Encryption key: {encryption_key}, File unique ID: {unique_file_id}")

#             # Receive and process message
#             async with asyncio.timeout(WEBSOCKET_TIMEOUT):
#                 request = await websocket.receive_json()
#             logger.info(f"Received request: {request}")
#             latest_req_id = request["id"]
            
#             # Update session activity
#             await session_manager.update_activity(session_id, latest_req_id)
#             async with asyncio.timeout(PROCESSING_TIMEOUT):
#             # Create and manage background task
#                 task = asyncio.create_task(compute_genai_response(request, websocket, session_id))
#                 background_tasks.add(task)
#                 task.add_done_callback(background_tasks.discard)
#     except asyncio.TimeoutError:
#         logger.error(f"WebSocket operation timeout for session {session_id}")
#         await send_error_message(websocket, "timeout", "Operation timed out")
#     except WebSocketDisconnect:
#         logger.info(f"WebSocket disconnected for session {session_id}")
#     except Exception as e:
#         logger.exception(f"Error in WebSocket connection: {e}")
#     finally:import os
import uuid
import asyncio
import secrets
from datetime import datetime, timedelta
from typing import Dict, Optional, List, Tuple
from fastapi import FastAPI, BackgroundTasks, WebSocket, HTTPException, UploadFile, File, APIRouter, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
import logging
from app.file_processor import FileProcessor

import aiofiles
from typing import AsyncGenerator, Dict
from fastapi import UploadFile, File, HTTPException, BackgroundTasks
import os
import logging
import uuid

import aiofiles
from typing import AsyncGenerator, Dict
from fastapi import UploadFile, File, HTTPException, BackgroundTasks
import os
import logging
import uuid

# Configuration Constants
UPLOAD_DIR = "uploads"
MAX_PDF_SIZE = 100 * 1024 * 1024  # 5 MB
MAX_DOCX_SIZE = 5 * 1024 * 1024  # 5 MB
MAX_IMAGE_SIZE = 2 * 1024 * 1024  # 2 MB
ALLOWED_EXTENSIONS = {
    'documents': ['.pdf', '.docx'],
    'images': ['.jpg', '.jpeg', '.png', '.gif']
}
WARNING_TIME = timedelta(minutes=1)
TIMEOUT_TIME = timedelta(minutes=2)
CLEANUP_INTERVAL = 10
BASE_PERSIST_DIR = "chroma_storage"

# Initialize logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Router setup
router = APIRouter(
    tags=["Skill"],
    responses={
        400: {"description": "Bad Request"},
        500: {"description": "Internal Server Error - da skills"},
    },
)


def create_app():
    """Create and configure FastAPI application"""
    app = FastAPI(
        title="Assistant",
        version="0.0.0",
        description="Assistant",
    )

    # Configure CORS
    origins = [
            "http://localhost:8000",
            "http://127.0.0.1:8000",
    ]

    app.add_middleware(
        CORSMiddleware,
        allow_origins=origins,
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    app.include_router(router=router)

    @app.on_event("startup")
    async def startup_event():
        """Initialize necessary services on startup"""
        logger.info("Starting Digital Assistant Skills service")
        logger.info("Triggering cleanup job")
        await session_manager.start_cleanup_task()

    @app.on_event("shutdown")
    async def shutdown_event():
        """Cleanup resources on application shutdown"""
        logger.info("Shutting down Digital Assistant Skills service")
        if session_manager.cleanup_task:
            session_manager.cleanup_task.cancel()
    
    return app

# First, let's define the SessionData class
class SessionData:
    """Session data storage class"""
    def __init__(self, client_id: str, encryption_key: str):
        self.client_id = client_id
        self.encryption_key = encryption_key
        self.file_unique_id = None
        self.files: Dict[str, Dict[str, str]] = {}
        self.last_activity = datetime.utcnow()
        self.warning_sent = False
        self.latest_req_id = 2

    def add_file(self, file_unique_id: str, file_name: str, file_description: str = ""):
        """Add file information to session"""
        self.files[file_unique_id] = {
            "file_name": file_name,
            "file_description": file_description
        }

    def update_activity(self, req_id: str):
        """Update session activity timestamp"""
        self.last_activity = datetime.utcnow()
        self.latest_req_id = req_id
        self.warning_sent = False

class SessionManager:
    """Manage WebSocket sessions and cleanup"""
    def __init__(self):
        self.sessions: Dict[str, SessionData] = {}
        self.client_session_map: Dict[str, str] = {}  # Maps client_id to session_id
        self.active_websockets: Dict[str, WebSocket] = {}  # Maps session_id to WebSocket
        self.cleanup_task: Optional[asyncio.Task] = None

    def create_session(self, websocket: WebSocket) -> Tuple[str, str]:
        """
        Create new session with websocket connection
        Returns:
            Tuple[str, str]: (session_id, client_id)
        """
        session_id = str(uuid.uuid4())
        client_id = str(uuid.uuid4())
        encryption_key = secrets.token_hex(16)
        
        # Initialize session data
        self.sessions[session_id] = SessionData(client_id, encryption_key)
        self.client_session_map[client_id] = session_id
        self.active_websockets[session_id] = websocket
        
        logger.info(f"Created new session. Session ID: {session_id}, Client ID: {client_id}")
        return session_id, client_id

    def get_session_by_client_id(self, client_id: str) -> Optional[SessionData]:
        """
        Retrieve session data using client ID
        Args:
            client_id: Client identifier
        Returns:
            Optional[SessionData]: Session data if found, None otherwise
        """
        session_id = self.client_session_map.get(client_id)
        if session_id:
            return self.sessions.get(session_id)
        return None

    def get_session_id_by_client_id(self, client_id: str) -> Optional[str]:
        """
        Get session ID using client ID
        Args:
            client_id: Client identifier
        Returns:
            Optional[str]: Session ID if found, None otherwise
        """
        return self.client_session_map.get(client_id)

    def get_session_by_id(self, session_id: str) -> Optional[SessionData]:
        """
        Retrieve session data using session ID
        Args:
            session_id: Session identifier
        Returns:
            Optional[SessionData]: Session data if found, None otherwise
        """
        return self.sessions.get(session_id)

    async def update_activity(self, session_id: str, latest_req_id: str):
        """
        Update session activity timestamp and request ID
        Args:
            session_id: Session identifier
            latest_req_id: Latest request identifier
        Raises:
            ValueError: If session ID is invalid
        """
        logger.info(f"Updating activity for session {session_id}")
        try:
            session = self.get_session_by_id(session_id)
            if session:
                session.update_activity(latest_req_id)
                logger.info(f"Updated activity for session {session_id} at {session.last_activity}")
            else:
                raise ValueError("Invalid session ID")
        except Exception as e:
            logger.error(f"Error updating activity for session {session_id}: {e}")
            raise

    async def cleanup_session(self, session_id: str):
        """
        Remove session and its associated data
        Args:
            session_id: Session identifier
        """
        if session_id in self.sessions:
            # Remove from active websockets
            self.active_websockets.pop(session_id, None)
            await purge_chroma_collections(session_id)
            # Remove client mapping
            client_id = self.sessions[session_id].client_id
            self.client_session_map.pop(client_id, None)
            
            # Remove session data
            del self.sessions[session_id]
            logger.info(f"Removed session {session_id}")

    async def start_cleanup_task(self):
        """Initialize the cleanup task"""
        if self.cleanup_task is None:
            self.cleanup_task = asyncio.create_task(self._cleanup_idle_sessions())
            logger.info("Started session cleanup task")

    async def _cleanup_idle_sessions(self):
        """
        Monitors and cleans up idle sessions
        - Checks session activity duration
        - Sends warning messages before timeout
        - Removes expired sessions
        """
        logger.info("Starting cleanup task")
        while True:
            try:
                current_time = datetime.utcnow()
                sessions_to_remove = []

                for session_id, session in self.sessions.items():
                    idle_duration = current_time - session.last_activity
                    latest_req_id = session.latest_req_id

                    logger.info(f"Session {session_id} idle for {idle_duration}")

                    if idle_duration >= TIMEOUT_TIME:
                        logger.info(f"Session {session_id} marked for removal due to inactivity")
                        sessions_to_remove.append(session_id)
                        websocket = self.active_websockets.get(session_id)

                        if websocket:
                            try:
                                await websocket.send_json({
                                    "id": latest_req_id,
                                    "chunk": "your session has expired due to inactivity, i will go",
                                    "end": False,
                                    "eventtype": "session_expiry",
                                    "channel": "main",
                                    "kb": "system"
                                })
                                logger.info(f"Session {session_id} expired due to inactivity")
                            except Exception as e:
                                logger.error(f"Error sending expiry message to session {session_id}: {e}")
                                sessions_to_remove.append(session_id)

                    elif idle_duration >= WARNING_TIME and not session.warning_sent:
                        # Send warning message
                        session.warning_sent = True
                        logger.info(f"Warning sent to session {session_id}")
                        websocket = self.active_websockets.get(session_id)
                        
                        if websocket:
                            try:
                                logger.info(f"Sending warning to session {session_id}")
                                remaining_mins = (TIMEOUT_TIME - idle_duration).seconds // 60
                                logger.info(f"idle_duration: {idle_duration}")
                                logger.info(f"Remaining minutes: {remaining_mins}")
                                
                                await websocket.send_json({
                                    "id": latest_req_id + 1,
                                    "chunk": f"your session will timeout in {remaining_mins} minutes",
                                    "end": False,
                                    "eventtype": "session_warning",
                                    "channel": "main",
                                    "kb": "system"
                                })
                                logger.info(f"Warning sent to session {session_id}: {remaining_mins}")
                            except Exception as e:
                                logger.error(f"Error sending warning to session {session_id}: {e}")
                                sessions_to_remove.append(session_id)

                # Clean up marked sessions
                for session_id in sessions_to_remove:
                    await self.cleanup_session(session_id)
                    logger.info(f"Session {session_id} cleaned up due to inactivity")

                # Wait before next cleanup check
                await asyncio.sleep(CLEANUP_INTERVAL)
            except Exception as e:
                logger.error(f"Error in cleanup: {e}")
                await asyncio.sleep(CLEANUP_INTERVAL)

# Initialize the session manager
session_manager = SessionManager()


async def get_file_type(filename: str) -> str:
    """
    Determine file type based on extension
    Args:
        filename: Name of the file
    Returns:
        str: File type ('document', 'image', or 'unknown')
    """
    ext = os.path.splitext(filename)[1].lower()
    if ext in ALLOWED_EXTENSIONS['documents']:
        return 'document'
    elif ext in ALLOWED_EXTENSIONS['images']:
        return 'image'
    return 'unknown'

# Cleanup utility
async def cleanup_temp_files():
    """Cleanup temporary files periodically"""
    while True:
        try:
            current_time = datetime.utcnow()
            for root, _, files in os.walk(UPLOAD_DIR):
                for file in files:
                    if file.endswith('.temp'):
                        file_path = os.path.join(root, file)
                        file_time = datetime.fromtimestamp(
                            os.path.getctime(file_path)
                        )
                        if current_time - file_time > timedelta(hours=1):
                            os.remove(file_path)
        except Exception as e:
            logger.error(f"Error in cleanup: {e}")
        finally:
            await asyncio.sleep(3600)  # Run every hour


async def purge_chroma_collections(file: str) -> dict:
    """Purge ChromaDB collections"""
    try:
        # Purge collections implementation would go here
        await asyncio.sleep(20)
        return {"status": "success", "message": "Successfully purged collections"}
    except Exception as e:
        logger.error(f"Error purging collections: {e}")
        raise
async def process_docx(file_path: str, unique_id: str) -> dict:
    """Process DOCX file and store in ChromaDB"""
    try:
        # DOCX processing implementation would go here
        return {"file_unique_id": unique_id}
    except Exception as e:
        logger.error(f"Error processing DOCX file: {e}")
        raise

async def process_image(file_path: str, unique_id: str) -> dict:
    """Process image file and store in ChromaDB"""
    try:
        # Image processing implementation would go here
        return {"file_unique_id": unique_id}
    except Exception as e:
        logger.error(f"Error processing image file: {e}")
        raise


from typing import AsyncGenerator, Dict, Optional
import asyncio
import time
import hashlib
from contextlib import asynccontextmanager

class ChunkUploadManager:
    def __init__(self):
        self.initial_chunk_size = 1024 * 1024  # 1MB initial chunk size
        self.min_chunk_size = 256 * 1024  # 256KB minimum
        self.max_chunk_size = 4 * 1024 * 1024  # 4MB maximum
        self.current_chunk_size = self.initial_chunk_size
        self.read_timeout = 30  # seconds
        self.max_retries = 3
        self.retry_delay = 1  # seconds

    @asynccontextmanager
    async def managed_upload(self, temp_path: str):
        """Context manager for handling file uploads"""
        try:
            async with aiofiles.open(temp_path, 'wb') as file:
                yield file
        except Exception as e:
            logger.error(f"Error in file upload: {e}")
            await cleanup_temp_file(temp_path)
            raise

    async def upload_chunk(self, chunk: bytes, file_handle, retry_count: int = 0) -> bool:
        """Upload a single chunk with retry logic"""
        try:
            await file_handle.write(chunk)
            return True
        except Exception as e:
            if retry_count < self.max_retries:
                logger.warning(f"Chunk write failed, attempt {retry_count + 1}/{self.max_retries}")
                await asyncio.sleep(self.retry_delay * (2 ** retry_count))  # Exponential backoff
                return await self.upload_chunk(chunk, file_handle, retry_count + 1)
            raise

    async def read_chunk_with_timeout(self, file: UploadFile) -> Optional[bytes]:
        """Read chunk with timeout handling"""
        try:
            return await asyncio.wait_for(
                file.read(self.current_chunk_size),
                timeout=self.read_timeout
            )
        except asyncio.TimeoutError:
            self._adjust_chunk_size(decrease=True)
            logger.warning(f"Read timeout, reduced chunk size to {self.current_chunk_size}")
            return None
        except Exception as e:
            logger.error(f"Error reading chunk: {e}")
            raise

    def _adjust_chunk_size(self, decrease: bool = False):
        """Dynamically adjust chunk size based on performance"""
        if decrease:
            self.current_chunk_size = max(
                self.min_chunk_size,
                self.current_chunk_size // 2
            )
        else:
            self.current_chunk_size = min(
                self.max_chunk_size,
                self.current_chunk_size * 2
            )

class FileUploadHandler:
    def __init__(self):
        self.chunk_manager = ChunkUploadManager()
        
    def calculate_checksum(self, data: bytes) -> str:
        """Calculate MD5 checksum of data"""
        return hashlib.md5(data).hexdigest()

    async def process_upload(
        self,
        file: UploadFile,
        temp_path: str,
        file_size_limit: int
    ) -> Dict:
        """Process file upload with resilience features"""
        start_time = time.time()
        total_size = 0
        checksum = hashlib.md5()
        
        async with self.chunk_manager.managed_upload(temp_path) as out_file:
            while True:
                chunk = await self.chunk_manager.read_chunk_with_timeout(file)
                if not chunk:
                    if total_size == 0:
                        raise HTTPException(
                            status_code=400,
                            detail="Empty or corrupted file"
                        )
                    break

                checksum.update(chunk)
                chunk_size = len(chunk)
                total_size += chunk_size

                if total_size > file_size_limit:
                    raise HTTPException(
                        status_code=400,
                        detail=f"File size exceeds limit of {file_size_limit / (1024 * 1024)}MB"
                    )

                await self.chunk_manager.upload_chunk(chunk, out_file)

                # Adjust chunk size based on performance
                elapsed = time.time() - start_time
                if elapsed > 0:
                    speed = total_size / elapsed
                    if speed > 5 * 1024 * 1024:  # If speed > 5MB/s
                        self.chunk_manager._adjust_chunk_size(decrease=False)
                    elif speed < 256 * 1024:  # If speed < 256KB/s
                        self.chunk_manager._adjust_chunk_size(decrease=True)

        return {
            "total_size": total_size,
            "checksum": checksum.hexdigest(),
            "upload_speed": total_size / (time.time() - start_time)
        }

@router.post("/liveai/digital/assistant-skills/upload-file/{client_id}")
async def upload_file(
    background_tasks: BackgroundTasks,
    client_id: str,
    file: UploadFile = File(...)
) -> Dict:
    """Handle file upload endpoint with enhanced resilience"""
    temp_file_path = None
    upload_handler = FileUploadHandler()
    
    try:
        # Session validation with timeout
        async with asyncio.timeout(SESSION_VALIDATION_TIMEOUT):
            session_id = session_manager.get_session_id_by_client_id(client_id)
            if not session_id:
                raise HTTPException(status_code=400, detail="Invalid client ID")
                
            session = session_manager.get_session_by_id(session_id)
            if not session:
                raise HTTPException(status_code=400, detail="Invalid session")

            await session_manager.update_activity(session_id, session.latest_req_id)


        async with asyncio.timeout(UPLOAD_TIMEOUT):

            # File type validation
            file_type = await get_file_type(file.filename)
            if file_type == 'unknown':
                raise HTTPException(
                    status_code=400,
                    detail=f"Unsupported file type. Allowed types: Documents: {', '.join(ALLOWED_EXTENSIONS['documents'])}, "
                        f"Images: {', '.join(ALLOWED_EXTENSIONS['images'])}"
                )

            # Prepare file paths
            os.makedirs(UPLOAD_DIR, exist_ok=True)
            unique_id = str(uuid.uuid4())
            safe_filename = f"{unique_id}_{secure_filename(file.filename)}"
            final_file_path = os.path.join(UPLOAD_DIR, safe_filename)
            temp_file_path = f"{final_file_path}.temp"

            # Process upload
            file_size_limit = MAX_PDF_SIZE if file_type == 'document' else MAX_IMAGE_SIZE
            upload_result = await upload_handler.process_upload(
                file=file,
                temp_path=temp_file_path,
                file_size_limit=file_size_limit
            )

        # Atomic file rename
        try:
            os.replace(temp_file_path, final_file_path)
        except Exception as e:
            logger.error(f"Error in atomic rename: {e}")
            if os.path.exists(temp_file_path):
                # Fallback to copy-then-delete if atomic rename fails
                async with aiofiles.open(temp_file_path, 'rb') as src:
                    async with aiofiles.open(final_file_path, 'wb') as dst:
                        await dst.write(await src.read())
                await cleanup_temp_file(temp_file_path)

        # Schedule background processing with retry handler
        background_tasks.add_task(
            handle_file_processing,
            final_file_path,
            client_id,
            unique_id
        )

        return {
            "filename": os.path.basename(file.filename),
            "file_unique_id": unique_id,
            "status": "success",
            "message": "File Upload Successful",
            "size": upload_result["total_size"],
            "checksum": upload_result["checksum"],
            "upload_speed_bps": upload_result["upload_speed"]
        }

    except asyncio.TimeoutError:
        logger.error("Session validation timeout")
        await cleanup_temp_file(temp_file_path)
        raise HTTPException(
            status_code=408,
            detail="Request timeout during session validation"
        )
    except HTTPException:
        await cleanup_temp_file(temp_file_path)
        raise
    except Exception as e:
        logger.error(f"Upload error: {str(e)}", exc_info=True)
        await cleanup_temp_file(temp_file_path)
        return {
            "status": "failed",
            "message": "Could not upload file at this time, please try again later",
            "error": str(e)
        }

def secure_filename(filename: str) -> str:
    """Make filename secure with enhanced validation"""
    # Remove any path components and null bytes
    filename = os.path.basename(filename).replace('\0', '')
    
    # Replace potentially dangerous characters with underscore
    filename = "".join(c if c.isalnum() or c in "._- " else "_" for c in filename)
    
    # Ensure filename doesn't start with a dot
    if filename.startswith('.'):
        filename = f"_" + filename[1:]
    
    # Limit length (255 - 37 for UUID)
    max_length = 218
    if len(filename) > max_length:
        name, ext = os.path.splitext(filename)
        filename = name[:max_length-len(ext)] + ext
        
    return filename.strip()

async def cleanup_temp_file(file_path: str) -> None:
    """Enhanced temporary file cleanup"""
    if not file_path or not os.path.exists(file_path):
        return

    max_retries = 3
    retry_delay = 1

    for attempt in range(max_retries):
        try:
            os.remove(file_path)
            logger.info(f"Cleaned up temporary file: {file_path}")
            return
        except PermissionError:
            if attempt < max_retries - 1:
                await asyncio.sleep(retry_delay * (2 ** attempt))
                continue
            logger.error(f"Permission error cleaning up file {file_path}")
        except Exception as e:
            logger.error(f"Error cleaning up temporary file {file_path}: {e}")
            break


from typing import Optional, Set, Dict, Any
from pydantic import BaseModel

class ConversationTurn(BaseModel):
    """Model for conversation turns"""
    role: str
    content: str

async def determine_intent(persona: str, skill: str, user_input: str, conversation_history: List[ConversationTurn]) -> Any:
    """
    Determine the intent of user input
    This is a placeholder for the actual intent determination logic
    """
    # Intent determination logic would go here
    return None

async def compute_genai_response(request: Dict[str, Any], websocket: WebSocket, session_id: str):
    """
    Compute and stream AI response
    Args:
        request: Request data from client
        websocket: WebSocket connection
        session_id: Session identifier
    """
    try:
        # Extract request data
        req_id = request["id"]
        user_input = request['question']
        conversation_history = [ConversationTurn(**turn) for turn in request['conversation_history']]
        custom_instruction = request.get('custom_instruction')
        logger.info(f"Conversation history: {conversation_history}")
        
        # Extract user context
        persona = request['digital_persona']
        skill = request['skill']
        intent = request.get('intent')
        speech_mode = request.get('speech_mode')
        input_file_unique_id = request.get('input_file_unique_id')
        output_file_unique_id = request.get('output_file_unique_id')
        image_base64 = request.get('image_base64')
        input_file_name = request.get('input_file_name')

        # Get session data
        session = session_manager.get_session_by_id(session_id)
        if not session:
            raise ValueError("Session not found")
            
        client_id = session.client_id
        encryption_key = session.encryption_key
        files = session.files
        
        logger.info(f"Client ID: {client_id}, Encryption key: {encryption_key}")
        for file_unique_id, file_info in files.items():
            logger.info(f"File Unique ID: {file_unique_id}, File Name: {file_info['file_name']}")
            
        logger.info(f"outside speech model mode: {speech_mode}")
        logger.info(f"inside speech mode: {speech_mode}")

        # Set default action and prompt
        action = "chitchat"
        prompt = "chitchat"
        standalone_question = user_input
        logger.info(f"User input: {user_input}")

        # Execute action
        await execute_action(req_id, persona, skill, action, prompt, standalone_question, conversation_history, websocket)

        logger.info(f"Response computed for request ID: {req_id}")
    except Exception as e:
        logger.exception(e)
        # Handle error response to client
        await send_error_message(websocket, req_id, str(e))

async def execute_action(req_id: str, persona: str, skill: str, action: str, prompt: str, 
                        standalone_question: str, conversation_history: List[ConversationTurn], websocket: WebSocket):
    """
    Execute the determined action
    This is a placeholder for action execution logic
    """
    #add delay of 5 seconds to simulate processing
    await asyncio.sleep(20)
    await websocket.send_json({
            "id": req_id,   
            "chunk": "IM HERE ALL DAY LONG",
            "end": True
        })
    pass

async def send_error_message(websocket: WebSocket, req_id: str, error_msg: str):
    """
    Send error message to client
    """
    try:
        await websocket.send_json({
            "id": req_id,
            "error": error_msg,
            "eventtype": "error",
            "channel": "main",
            "kb": "system"
        })
    except Exception as e:
        logger.error(f"Error sending error message: {e}")

@router.websocket("/liveai/digital/assistant-skills/stream")
async def stream(websocket: WebSocket):
    """
    Handle WebSocket connection for streaming responses
    Args:
        websocket: WebSocket connection
    """
    await websocket.accept()
    session_id, client_id = session_manager.create_session(websocket)

    logger.info(f"WebSocket connection established for session {session_id}")
    logger.info(f"Generated client_id: {client_id}")

    # Send initial session information to the client
    await websocket.send_json({
        "eventtype": "init_session",
        "client_id": client_id,
        "channel": "contextmemory",
    })

    background_tasks: Set[asyncio.Task] = set()
    try:
        while True:
            # Get session data
            session = session_manager.get_session_by_client_id(client_id)
            session_id = session_manager.get_session_id_by_client_id(client_id)
            encryption_key = session.encryption_key
            unique_file_id = session.file_unique_id

            logger.info(f"Session ID: {session_id}, Encryption key: {encryption_key}, File unique ID: {unique_file_id}")

            # Receive and process message
            request = await websocket.receive_json()
            logger.info(f"Received request: {request}")
            latest_req_id = request["id"]
            
            # Update session activity
            await session_manager.update_activity(session_id, latest_req_id)
            
            # Create and manage background task
            task = asyncio.create_task(compute_genai_response(request, websocket, session_id))
            background_tasks.add(task)
            task.add_done_callback(background_tasks.discard)

    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected for session {session_id}")
    except Exception as e:
        logger.exception(f"Error in WebSocket connection: {e}")
    finally:
        # Cleanup tasks and session
        # for task in background_tasks:
        #     task.cancel()
        # logger.info("Going to cleanup the sessions")
        # await session_manager.cleanup_session(session_id)
        # logger.info("WebSocket closed")
        for task in background_tasks:
            if not task.done():
                task.cancel()
        
        # Wait for tasks to complete cancellation
        if background_tasks:
            await asyncio.gather(*background_tasks, return_exceptions=True)
        
        if session_id:
            # Schedule cleanup as a background task
            asyncio.create_task(
                handle_session_cleanup(session_id)
            )
        
        logger.info("WebSocket stream handler completed")

async def handle_session_cleanup(session_id: str):
    """
    Handle session cleanup in the background
    Args:
        session_id: Session identifier
    """
    try:
        logger.info(f"Starting cleanup for session {session_id}")
        
        # 1. Cancel any pending tasks for this session
        # 2. Cleanup session data
        await session_manager.cleanup_session(session_id)
        
        logger.info(f"Completed cleanup for session {session_id}")
        
    except Exception as e:
        logger.error(f"Error during session cleanup: {e}", exc_info=True)
        # Even if cleanup fails, we don't want to block the websocket
        # The cleanup task manager will retry or handle failures separately
        # Cleanup tasks and session
        # for task in background_tasks:
        #     task.cancel()
        # logger.info("Going to cleanup the sessions")
        # await session_manager.cleanup_session(session_id)
        # logger.info("WebSocket closed")
        for task in background_tasks:
            if not task.done():
                task.cancel()
        
        # Wait for tasks to complete cancellation
        if background_tasks:
            await asyncio.gather(*background_tasks, return_exceptions=True)
        
        if session_id:
            # Schedule cleanup as a background task
            asyncio.create_task(
                handle_session_cleanup(session_id)
            )
        
        logger.info("WebSocket stream handler completed")

async def handle_session_cleanup(session_id: str):
    """
    Handle session cleanup in the background
    Args:
        session_id: Session identifier
    """
    try:
        logger.info(f"Starting cleanup for session {session_id}")
        
        # 1. Cancel any pending tasks for this session
        # 2. Cleanup session data
        await session_manager.cleanup_session(session_id)
        
        logger.info(f"Completed cleanup for session {session_id}")
        
    except Exception as e:
        logger.error(f"Error during session cleanup: {e}", exc_info=True)
        # Even if cleanup fails, we don't want to block the websocket
        # The cleanup task manager will retry or handle failures separately
